Simple Tutorial for Hugging Face Transformers
Hugging Face is a popular open-source platform and library for working with state-of-the-art machine learning models, especially transformers for natural language processing (NLP), computer vision, audio, and more. The easiest way to get started is with the Transformers library and its pipeline function, which lets you use pre-trained models with just a few lines of codeâ€”no training required!
Step 1: Installation
First, install the library (run this in your terminal or notebook):
Bashpip install transformers
(Optional: For GPU support, also install PyTorch with CUDA if you have a compatible GPU.)
Step 2: Basic Usage with Pipeline
The pipeline is the simplest API. It automatically downloads a suitable pre-trained model and handles everything for common tasks.
Here are some simple examples:

Sentiment Analysis (detect positive/negative emotion in text):

Pythonfrom transformers import pipeline

classifier = pipeline("sentiment-analysis")

result = classifier("I love using Hugging Face! It's amazing.")
print(result)
# Output: [{'label': 'POSITIVE', 'score': 0.9998}]

result = classifier("This is terrible.")
print(result)
# Output: [{'label': 'NEGATIVE', 'score': 0.9995}]
You can pass a list for multiple texts:
Pythonresults = classifier(["Hugging Face is great!", "I hate bugs in code."])
print(results)
# Output: [{'label': 'POSITIVE', ...}, {'label': 'NEGATIVE', ...}]

Text Generation (continue or generate text):

Pythonfrom transformers import pipeline

generator = pipeline("text-generation", model="gpt2")  # You can specify a model like "gpt2"

output = generator("Once upon a time in a galaxy far away,", max_length=50)
print(output[0]['generated_text'])
# Example output: "Once upon a time in a galaxy far away, there was a young Jedi named Luke Skywalker who..."

Translation (English to French):

Pythonfrom transformers import pipeline

translator = pipeline("translation_en_to_fr")

output = translator("Hello, how are you today?")
print(output[0]['translation_text'])
# Output: "Bonjour, comment allez-vous aujourd'hui ?"

Question Answering (answer based on context):

Pythonfrom transformers import pipeline

qa = pipeline("question-answering")

context = "Hugging Face is a company based in New York that creates AI tools."
question = "Where is Hugging Face based?"

result = qa(question=question, context=context)
print(result['answer'])
# Output: "New York"

Summarization (shorten long text):

Pythonfrom transformers import pipeline

summarizer = pipeline("summarization")

text = """Hugging Face is an open-source library that makes it easy to use transformer models.
It has thousands of pre-trained models for tasks like text classification, generation, and more."""

summary = summarizer(text, max_length=50, min_length=20)
print(summary[0]['summary_text'])
# Example: "Hugging Face is an open-source library for transformer models with thousands available."
Tips

The first run downloads the model (can take time; subsequent runs are fast as it's cached).
Specify a model parameter (e.g., "distilbert-base-uncased-finetuned-sst-2-english" for sentiment) for custom models.
Explore more tasks: "ner" (named entity recognition), "fill-mask", "zero-shot-classification", etc.
For advanced use (fine-tuning, custom models), check the official docs at https://huggingface.co/docs/transformers.

This is just the beginningâ€”Hugging Face has over 500,000 models on their Hub! Try experimenting with different tasks and models. Have fun! ðŸš€
